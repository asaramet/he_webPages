<h1>Batch Jobs on bwGRiD Cluster Esslingen</h1>
<p>At Esslingen University of Applied Sciences, bwGRiD high performance computing cluster uses the 
  TORQUE resource manager (based on OpenPBS) and the Moab Workload Manager to manage and schedule jobs.
</p>
<h2>TORQUE overview</h2>
<p>
  TORQUE is a resource management system for submitting and controlling jobs on HPC 
  clusters. It manages jobs submitted to various queues on a computing system, each queue
  representing a group of resources with attributes necessary for the job.
</p>
<p>Commonly used TORQUE commands include:</p>
<table class="bash">
  <tr>
    <td><kbd>qsub</kbd></td>
    <td>Submit Job</td>
  </tr>
  <tr>
    <td><kbd>qstat</kbd></td>
    <td>Monitor the status of a job</td>
  </tr>
  <tr>
    <td><kbd>qdel</kbd></td>
    <td>Terminate a job prior to it's completion</td>
  </tr>
</table>
<p>TORQUE includes numerous directives, which are used to specify resource requirements and other 
 attributes for batch and interactive jobs. This directives can appear as header lines (which start
 with <kbd>#PBS</kbd>) in a batch job script or as command-line options to the <kbd>qsub</kbd> command.
</p>
<h2>Job scripts</h2>
<p>To run a job in batch mode on a high-performance computing system using TORQUE, first prepare a job 
 script that specifies the application you want to run and the resources required to run it, then submit 
 the script to TORQUE using <kbd>qsub</kbd> command. TORQUE passes your job and its requirements to the 
 system's job scheduler, which then dispatches your job whenever the required resources are available.
</p>
<p>A very basic job script might contain just a bash shell script. However, TORQUE job scripts most 
 commonly contain at least one executable command preceded by a list of directives that specify resources 
 and other attributes needed to execute the command (e.g., wall-clock time, the number of nodes and 
 processors, and filenames for job outputs and errors). These directives are listed in header lines 
 (lines beginning with <kbd>#PBS</kbd>), which should precede any executable lines in your job script.
</p>
<p>Additionally, your TORQUE job script should begin with a line that specifies the command interpreter 
 under which it should run.
</p>
<p>For example, a TORQUE job script for an MPI job might look like this:</p>
<pre>
#!/bin/bash
#PBS -k o
#PBS -l nodes=2:ppn=8:mem24gb
#PBS -l walltime=00:30:00
#PBS -M kenobi@hs-esslingen.de
#PBS -m abe
#PBS -N JobName
#PBS -j oe

mpiexec -mp 16 -machinefile $PBS_NODEFILE ~/bin/binaryname
</pre>
<p>In the example above, the first line indicates that the script should be read using <kbd>bash</kbd>
 command interpreter. Then, several header lines of TORQUE directives are included:
</p>
<table class="describe">
  <tr>
    <th>TORQUE directive</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><kbd>#PBS -k o</kbd>
    <td>Keeps the job output</td>
  </tr>
  <tr>
    <td><kbd>#PBS -l nodes=2:ppn=8:mem24gb</kbd></td>
    <td>Indicates the job requires 2 nodes, and 8 processors per node. And requests nodes with 24GB RAM*
    </td>
  </tr>
  <tr>
    <td><kbd>#PBS -l walltime=00:30:00</kbd></td>
    <td>Indicated the job requires 30 minutes of wall-clock time to run</td>
  </tr>
  <tr>
    <td><kbd>#PBS -M kenobi@hs-esslingen.de</kbd></td>
    <td>Sends job-related email to <kbd>kenobi@hs-esslingen.de</kbd></td>
  </tr>
  <tr>
    <td><kbd>#PBS -m abe</kbd></td>
    <td>Sends email if the job is (<kbd>a</kbd>) aborted, (<kbd>b</kbd>) begins, and when it 
     (<kbd>e</kbd>) ends</td>
  </tr>
  <tr>
    <td><kbd>#PBS -N JobName</kbd></td>
    <td>Names the job <kbd>JobName</kbd></td>
  </tr>
  <tr>
    <td><kbd>#PBS -j oe</kbd></td>
    <td>Joins standard output and standard error</td>
  </tr>
</table>
<p>The last line in the example is the executable line. It tells the operating system to use 
 <kbd>mpiexec</kbd> command to execute <kbd>~/bin/binaryname</kbd> binary on 16 processors from the
 machines listed in <kbd>$PBS_NODEFILE</kbd>
</p>
<p>
 <strong>*</strong> 
 Currently there are 2 types of nodes available on the cluster: nodes with 24GB RAM (<kbd>mem24gb</kbd>)
 and nodes with 64GB RAM (<kbd>mem64gb</kbd>). The 64GB RAM nodes are considerably less then 24GB RAM nodes, 
 and you may have to wait longer before your job starts. You can request up to maximum 8 processors for each
 node with 24GB RAM, and 16 processors for each node with 64GB RAM.
</p>
<p>For more TORQUE directives, see the <kbd>qsub</kbd> manual page (enter <kbd>man qsub</kbd>)</p>
<h2>Submitting jobs</h2>
<p>To submit you job script (e.g., <kbd>job.pbs</kbd>), use the TORQUE <kbd>qsub</kbd> command.
 If the command runs successfully, it will return a job ID to standard output, for example:
</p>
<pre>
qsub job.pbs
579883.intern1
</pre>
<p>If your job requires attribute values greater than the defaults, but less than the maximum allowed,
 you can specify these with the <kbd>-l</kbd> (lowercase <kbd>L</kbd>, for "limit") option, either in your
 job script (as explained in the previous section) or on the <kbd>qsub</kbd> command line. For example,
 the following command submits <kbd>job.pbs</kbd>, using the <kbd>-l walltime</kbd> option to indicate
 the job needs more than the default 30 minutes on wall-clock time:
</p>
<pre>
qsub -l walltime=10:00:00 job.pbs
</pre>
<p><strong>Note:</strong> Command-line options will overwrite TORQUE directives in your job script.</p>
<p>To include multiple options on the command line, use either one -l flag with several comma-separated 
 options, or multiple <kbd>-l</kbd> flags, each separated by a space. For example, the following two 
 command are equivalent:
</p>
<pre>
qsub -l nodes=2:ppn=8:mem24gb,walltime=24:00:00 job.pbs
qsub -l nodes=2:ppn=8:mem24gb -l walltime=24:00:00 job.pbs
</pre>
<p>Useful <kbd>qsub</kbd> options include:
<table class="describe">
  <tr>
    <th><kbd>qsub</kbd> option</th>
    <th>Description</kbd>
  </tr>
  <tr>
    <td><kbd>-q queue_name</kbd></td>
    <td>Specifies a user-selectable queue (<kbd>queue_name</kbd>)</td>
  </tr>
  <tr>
    <td><kbd>-r</kbd></td>
    <td>Makes the job re-runnable</td>
  </tr>
  <tr>
    <td><kbd>-a date_time</kbd></td>
    <td>Executes the job only after a specific date and time (<kbd>date_time</kbd>)</td>
  </tr>
  <tr>
    <td><kbd>-V</kbd></td>
    <td>Exports environment variables in your current environment to the job</td>
  </tr>
  <tr>
    <td><kbd>-I</kbd></td>
    <td>Makes the job run interactively (usually for testing purposes)</td>
  </tr>
</table>
<h2>Monitoring jobs</h2>
<p>To monitor the status of a queued or running job, use the <kbd>qstat</kbd> command.</p>
<p>Useful <kbd>qstat</kbd> options include:</p>
<table class="describe">
  <tr>
    <th><kbd>qstat</kbd> option</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><kbd>-u user_list</kbd></td>
    <td>Displays jobs for users listed in <kbd>user_list</kbd>
  </tr>
  <tr>
    <td><kbd>-a</kbd></td>
    <td>Displays all jobs</td>
  </tr>
  <tr>
    <td><kbd>-r</kbd></td>
    <td>Displays running jobs</td>
  </tr>
  <tr>
    <td><kbd>-f</kbd></td>
    <td>Displays the full listing of jobs (returns excessive detail)</td>
  </tr>
  <tr>
    <td><kbd>-n</kbd></td>
    <td>Displays nodes allocated to the jobs</td>
  </tr>
</table>
<p>For example, to see all the jobs running in the <kbd>bw-multi</kbd> queue, enter:</p>
<pre>qstat -r bw-multi</pre>
<p>For more, see the <kbd>qstat</kbd> manual page (enter <kbd>man qstat</kbd>).
<h2>Deleting jobs</h2>
<p>To delete queued or running jobs, use <kbd>qdel</kbd> command:</p>
<ul>
  <li>To delete a specific job (<kbd>jobid</kbd>), enter:</li>
    <pre>qdel jobid</pre>
  <li>Occasionally, a node becomes unresponsive to the TORQUE server's request to delete a job.
   If that occurs, add the <kbd>-W</kbd> (uppercase W) option:</li>
    <pre>qdel -W jobid</pre>
</ul>
<p>For more, see the <kbd>qdel</kbd> manual page (enter <kbd>man qdel</kbd>).</p>
<h2>Common Moab scheduler commands</h2>
<p>For jobs monitoring and status, alternatively Moab scheduler commands can be used.
  Frequently used Moab commands include:
</p>
<table class="describe">
  <tr>
    <th>Moab command</th>
    <th>Function</th>
  </tr>
  <tr>
    <td><kbd>showq</kbd></td>
    <td>Display the jobs in the Moab job queue. (Jobs may be in a number of states;
      "Running" and "Idle" are the most common.)
    </td>
  </tr>
  <tr>
    <td><kbd>checkjob jobid</kbd></td>
    <td>Check the status of a job (<kbd>jobid</kbd>). For verbose mode, add
      <kbd>-v</kbd> <br/>(e.g., <kbd>checkjob -v jobid</kbd>).
    </td>
  </tr>
  <tr>
    <td><kbd>showstart jobid</kbd></td>
    <td>Show an estimate of when your job (<kbd>jobid</kbd>) might start.</td>
  </tr>
  <tr>
    <td><kbd>showres</kbd></td>
    <td>Show the current reservations</td>
  </tr>
  <tr>
    <td><kbd>showbf</kbd></td>
    <td>Show intervals and node counts presently available for backfill jobs.</td>
  </tr>
</table>
<p>For more Moab commands and their descriptions, see the Adaptive Computing 
  <a target="_blank" href="http://docs.adaptivecomputing.com/mwm/7-1-3/help.htm#a.gcommandoverview.html">
   Scheduler Commands page</a>
</p>
